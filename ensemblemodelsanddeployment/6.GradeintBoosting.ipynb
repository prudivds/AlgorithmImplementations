{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Office\n",
    "os.chdir('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\NITDATA\\\\Algorithms\\\\codesnippetsforbaggingandboostingalgorithms')\n",
    "data = pd.read_csv('train_u6lujuX_CVtuZ9i.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle\n",
    "\n",
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ## Here this model will be called with a variable (df), which is a dataframe\n",
    "    def datapreprocessing(self, df):\n",
    "        \n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        df.loc[df['Gender'].isnull(),'Gender']='Trasgender'\n",
    "        df.loc[df['Dependents'].isnull(),'Dependents']='0'\n",
    "        df.loc[df['Education'].isnull(),'Education']='No Education'\n",
    "        df.loc[df['Married'].isnull(),'Married']='No'\n",
    "        df.loc[df['Self_Employed'].isnull(),'Self_Employed']='No'\n",
    "        df.loc[df['Loan_Amount_Term'].isnull(),'Loan_Amount_Term']=0\n",
    "        df.loc[df['Credit_History'].isnull(),'Credit_History']=0\n",
    "        df.loc[df['LoanAmount'].isnull(),'LoanAmount']=146.867     \n",
    "        df['Credit_History']=df['Credit_History'].astype(str)\n",
    "        \n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        MinMaxpickle_in = open(\"minmax_pickle.pkl\",\"rb\")\n",
    "        MinmaxScaler_dict = pickle.load(MinMaxpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['ApplicantIncome']=pd.DataFrame(MinmaxScaler_dict['ApplicantIncome'].transform(df[['ApplicantIncome']]))\n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        standardscaler_in = open(\"standardscaler_pickle.pkl\",\"rb\")\n",
    "        standardscaler_dict = pickle.load(standardscaler_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['LoanAmount']=pd.DataFrame(standardscaler_dict['LoanAmount'].transform(df[['LoanAmount']]))\n",
    "        \n",
    "        ## Creating a Instance for the LabelEncoder Pickle File\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Education']=pd.DataFrame(Labelencoder_dict['Education'].transform(df[['Education']]))\n",
    "        df['Property_Area']=pd.DataFrame(Labelencoder_dict['Property_Area'].transform(df[['Property_Area']]))\n",
    "        df['Credit_History']=pd.DataFrame(Labelencoder_dict['Credit_History'].transform(df[['Credit_History']]))\n",
    "        df['Dependents']=pd.DataFrame(Labelencoder_dict['Dependents'].transform(df[['Dependents']]))\n",
    "        \n",
    "        ## Creating a Instance for the binarizer Pickle File\n",
    "        Onehotpickle_in = open(\"binarizer_pickle.pkl\",\"rb\")\n",
    "        Onehot_dict = pickle.load(Onehotpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        d1=pd.DataFrame(Onehot_dict['Self_Employed'].transform(df[['Self_Employed']]))\n",
    "        d1.columns=['Self_Employed_0']\n",
    "        d2=pd.DataFrame(Onehot_dict['Married'].transform(df[['Married']]))\n",
    "        d2.columns=['Married_0']\n",
    "        d3=pd.DataFrame(Onehot_dict['Gender'].transform(df[['Gender']]))\n",
    "        d3.columns=['Gender_0','Gender_1','Gender_2']\n",
    "    \n",
    "        df=df.drop(['Self_Employed','Married','Gender','Loan_ID'],axis=1)\n",
    "        df=pd.concat([df,d1,d2,d3],axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def definingvalues(self, df, y=None,**fit_params):\n",
    "        self.term_mean_ = df['Loan_Amount_Term'].mean()\n",
    "        self.amt_mean_ = df['LoanAmount'].mean()\n",
    "        return self\n",
    "    \n",
    "    def encodingTargetVariable(self,df):\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Loan_Status']=pd.DataFrame(Labelencoder_dict['Loan_Status'].transform(df[['Loan_Status']]))\n",
    "        \n",
    "        return df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
       "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_var = ['Loan_ID','Gender','Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History', 'Property_Area']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[pred_var], data['Loan_Status'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating an instance for the class\n",
    "preprocess = PreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreProcessing()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the fit function present in the class Preprocessing\n",
    "preprocess.definingvalues(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 13)\n",
      "(429, 12)\n"
     ]
    }
   ],
   "source": [
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_train dataset\n",
    "data_transformed_xtrain = preprocess.datapreprocessing(X_train)\n",
    "\n",
    "pred_var = ['Dependents', 'Education', 'ApplicantIncome',\n",
    "       'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History',\n",
    "       'Property_Area', 'Self_Employed_0', 'Married_0', 'Gender_0', 'Gender_1','Gender_2']\n",
    "\n",
    "\n",
    "data_transformed_xtrain=pd.DataFrame(data_transformed_xtrain,columns=pred_var)\n",
    "data_transformed_xtrain.head()\n",
    "\n",
    "print(data_transformed_xtrain.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dependents', 'Education', 'ApplicantIncome', 'CoapplicantIncome',\n",
       "       'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area',\n",
       "       'Self_Employed_0', 'Married_0', 'Gender_0', 'Gender_1', 'Gender_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformed_xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Self_Employed_0</th>\n",
       "      <th>Married_0</th>\n",
       "      <th>Gender_0</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Gender_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.426199</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.108986</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306361</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>0.329638</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.033230</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.048895</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependents  Education  ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
       "0           0          0         0.681284                0.0    1.426199   \n",
       "1           0          0         0.317267                0.0   -0.108986   \n",
       "2           2          0         0.306361             1447.0    0.329638   \n",
       "3           0          0         0.209732                0.0   -1.033230   \n",
       "4           0          0         0.195851                0.0   -1.048895   \n",
       "\n",
       "   Loan_Amount_Term  Credit_History  Property_Area  Self_Employed_0  \\\n",
       "0             360.0               1              1                0   \n",
       "1             360.0               0              1                0   \n",
       "2             360.0               1              0                0   \n",
       "3             360.0               1              0                0   \n",
       "4             360.0               1              1                0   \n",
       "\n",
       "   Married_0  Gender_0  Gender_1  Gender_2  \n",
       "0          1         0         1         0  \n",
       "1          1         0         1         0  \n",
       "2          1         0         1         0  \n",
       "3          0         1         0         0  \n",
       "4          0         0         1         0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_test dataset\n",
    "data_transformed_xtest = preprocess.datapreprocessing(X_test)\n",
    "\n",
    "# Converting the matrix to a dataframe\n",
    "data_transformed_xtest=pd.DataFrame(data_transformed_xtest,columns=pred_var)\n",
    "data_transformed_xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.DataFrame(y_train).reset_index(drop=True)\n",
    "y_train.columns=['Loan_Status']\n",
    "\n",
    "y_test=pd.DataFrame(y_test).reset_index(drop=True)\n",
    "y_test.columns=['Loan_Status']\n",
    "\n",
    "y_train=preprocess.encodingTargetVariable(y_train)\n",
    "y_test=preprocess.encodingTargetVariable(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.01, loss='deviance', max_depth=20,\n",
       "                           max_features=None, max_leaf_nodes=15,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=0.1, min_samples_split=0.6,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=5,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC=GradientBoostingClassifier(learning_rate=0.01,n_estimators=5,\n",
    "                               min_samples_split=0.6,min_samples_leaf=0.1,max_depth=20,max_leaf_nodes=15)\n",
    "\n",
    "GBC.fit(data_transformed_xtrain,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "\n",
    "min_samples_split\n",
    "Defines the minimum number of samples (or observations) which are required in a node to be considered for splitting.\n",
    "Used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree.\n",
    "\n",
    "min_samples_leaf\n",
    "Defines the minimum samples required in a terminal or leaf node.\n",
    "Generally, lower values should be chosen for imbalanced class problems because the regions in which the minority class will be in the majority will be very small.\n",
    "\n",
    "min_weight_fraction_leaf\n",
    "Similar to min_samples_leaf but defined as a fraction of the total number of observations instead of an integer.\n",
    "\n",
    "max_depth\n",
    "The maximum depth of a tree.\n",
    "Used to control over-fitting as higher depth will allow the model to learn relations very specific to a particular sample.\n",
    "Should be tuned using CV.\n",
    "\n",
    "max_leaf_nodes\n",
    "The maximum number of terminal nodes or leaves in a tree.\n",
    "Can be defined in place of max_depth. Since binary trees are created, a depth of ‘n’ would produce a maximum of 2^n leaves.\n",
    "If this is defined, GBM will ignore max_depth.\n",
    "\n",
    "max_features\n",
    "The number of features to consider while searching for the best split. These will be randomly selected.\n",
    "As a thumb-rule, the square root of the total number of features works great but we should check up to 30-40% of the total number of features.\n",
    "Higher values can lead to over-fitting but it generally depends on a case to case scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=20,\n",
       "                      max_features=None, max_leaf_nodes=15,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=0.1, min_samples_split=0.6,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=<mtrand.RandomState object at 0x0000020A5EE8F458>,\n",
       "                      splitter='best')],\n",
       "       [DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=20,\n",
       "                      max_features=None, max_leaf_nodes=15,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=0.1, min_samples_split=0.6,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=<mtrand.RandomState object at 0x0000020A5EE8F458>,\n",
       "                      splitter='best')],\n",
       "       [DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=20,\n",
       "                      max_features=None, max_leaf_nodes=15,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=0.1, min_samples_split=0.6,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=<mtrand.RandomState object at 0x0000020A5EE8F458>,\n",
       "                      splitter='best')],\n",
       "       [DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=20,\n",
       "                      max_features=None, max_leaf_nodes=15,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=0.1, min_samples_split=0.6,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=<mtrand.RandomState object at 0x0000020A5EE8F458>,\n",
       "                      splitter='best')],\n",
       "       [DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=20,\n",
       "                      max_features=None, max_leaf_nodes=15,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=0.1, min_samples_split=0.6,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=<mtrand.RandomState object at 0x0000020A5EE8F458>,\n",
       "                      splitter='best')]], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.93713492, 0.06286508, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sklearn.ensemble._gb_losses.BinomialDeviance object at 0x0000020A63C96A08>\n"
     ]
    }
   ],
   "source": [
    "print(GBC.loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
