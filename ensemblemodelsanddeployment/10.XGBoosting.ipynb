{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Office\n",
    "os.chdir('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\NITDATA\\\\Algorithms\\\\codesnippetsforbaggingandboostingalgorithms')\n",
    "data = pd.read_csv('train_u6lujuX_CVtuZ9i.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle\n",
    "\n",
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ## Here this model will be called with a variable (df), which is a dataframe\n",
    "    def datapreprocessing(self, df):\n",
    "        \n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        df.loc[df['Gender'].isnull(),'Gender']='Trasgender'\n",
    "        df.loc[df['Dependents'].isnull(),'Dependents']='0'\n",
    "        df.loc[df['Education'].isnull(),'Education']='No Education'\n",
    "        df.loc[df['Married'].isnull(),'Married']='No'\n",
    "        df.loc[df['Self_Employed'].isnull(),'Self_Employed']='No'\n",
    "        df.loc[df['Loan_Amount_Term'].isnull(),'Loan_Amount_Term']=0\n",
    "        df.loc[df['Credit_History'].isnull(),'Credit_History']=0\n",
    "        df.loc[df['LoanAmount'].isnull(),'LoanAmount']=146.867     \n",
    "        df['Credit_History']=df['Credit_History'].astype(str)\n",
    "        \n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        MinMaxpickle_in = open(\"minmax_pickle.pkl\",\"rb\")\n",
    "        MinmaxScaler_dict = pickle.load(MinMaxpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['ApplicantIncome']=pd.DataFrame(MinmaxScaler_dict['ApplicantIncome'].transform(df[['ApplicantIncome']]))\n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        standardscaler_in = open(\"standardscaler_pickle.pkl\",\"rb\")\n",
    "        standardscaler_dict = pickle.load(standardscaler_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['LoanAmount']=pd.DataFrame(standardscaler_dict['LoanAmount'].transform(df[['LoanAmount']]))\n",
    "        \n",
    "        ## Creating a Instance for the LabelEncoder Pickle File\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Education']=pd.DataFrame(Labelencoder_dict['Education'].transform(df[['Education']]))\n",
    "        df['Property_Area']=pd.DataFrame(Labelencoder_dict['Property_Area'].transform(df[['Property_Area']]))\n",
    "        df['Credit_History']=pd.DataFrame(Labelencoder_dict['Credit_History'].transform(df[['Credit_History']]))\n",
    "        df['Dependents']=pd.DataFrame(Labelencoder_dict['Dependents'].transform(df[['Dependents']]))\n",
    "        \n",
    "        ## Creating a Instance for the binarizer Pickle File\n",
    "        Onehotpickle_in = open(\"binarizer_pickle.pkl\",\"rb\")\n",
    "        Onehot_dict = pickle.load(Onehotpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        d1=pd.DataFrame(Onehot_dict['Self_Employed'].transform(df[['Self_Employed']]))\n",
    "        d1.columns=['Self_Employed_0']\n",
    "        d2=pd.DataFrame(Onehot_dict['Married'].transform(df[['Married']]))\n",
    "        d2.columns=['Married_0']\n",
    "        d3=pd.DataFrame(Onehot_dict['Gender'].transform(df[['Gender']]))\n",
    "        d3.columns=['Gender_0','Gender_1','Gender_2']\n",
    "    \n",
    "        df=df.drop(['Self_Employed','Married','Gender','Loan_ID'],axis=1)\n",
    "        df=pd.concat([df,d1,d2,d3],axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def definingvalues(self, df, y=None,**fit_params):\n",
    "        self.term_mean_ = df['Loan_Amount_Term'].mean()\n",
    "        self.amt_mean_ = df['LoanAmount'].mean()\n",
    "        return self\n",
    "    \n",
    "    def encodingTargetVariable(self,df):\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Loan_Status']=pd.DataFrame(Labelencoder_dict['Loan_Status'].transform(df[['Loan_Status']]))\n",
    "        \n",
    "        return df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
       "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_var = ['Loan_ID','Gender','Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History', 'Property_Area']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[pred_var], data['Loan_Status'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating an instance for the class\n",
    "preprocess = PreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreProcessing()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the fit function present in the class Preprocessing\n",
    "preprocess.definingvalues(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 13)\n",
      "(429, 12)\n"
     ]
    }
   ],
   "source": [
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_train dataset\n",
    "data_transformed_xtrain = preprocess.datapreprocessing(X_train)\n",
    "\n",
    "pred_var = ['Dependents', 'Education', 'ApplicantIncome',\n",
    "       'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History',\n",
    "       'Property_Area', 'Self_Employed_0', 'Married_0', 'Gender_0', 'Gender_1','Gender_2']\n",
    "\n",
    "\n",
    "data_transformed_xtrain=pd.DataFrame(data_transformed_xtrain,columns=pred_var)\n",
    "data_transformed_xtrain.head()\n",
    "\n",
    "print(data_transformed_xtrain.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dependents', 'Education', 'ApplicantIncome', 'CoapplicantIncome',\n",
       "       'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area',\n",
       "       'Self_Employed_0', 'Married_0', 'Gender_0', 'Gender_1', 'Gender_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformed_xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Self_Employed_0</th>\n",
       "      <th>Married_0</th>\n",
       "      <th>Gender_0</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Gender_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.426199</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.108986</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306361</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>0.329638</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.033230</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.048895</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependents  Education  ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
       "0           0          0         0.681284                0.0    1.426199   \n",
       "1           0          0         0.317267                0.0   -0.108986   \n",
       "2           2          0         0.306361             1447.0    0.329638   \n",
       "3           0          0         0.209732                0.0   -1.033230   \n",
       "4           0          0         0.195851                0.0   -1.048895   \n",
       "\n",
       "   Loan_Amount_Term  Credit_History  Property_Area  Self_Employed_0  \\\n",
       "0             360.0               1              1                0   \n",
       "1             360.0               0              1                0   \n",
       "2             360.0               1              0                0   \n",
       "3             360.0               1              0                0   \n",
       "4             360.0               1              1                0   \n",
       "\n",
       "   Married_0  Gender_0  Gender_1  Gender_2  \n",
       "0          1         0         1         0  \n",
       "1          1         0         1         0  \n",
       "2          1         0         1         0  \n",
       "3          0         1         0         0  \n",
       "4          0         0         1         0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_test dataset\n",
    "data_transformed_xtest = preprocess.datapreprocessing(X_test)\n",
    "\n",
    "# Converting the matrix to a dataframe\n",
    "data_transformed_xtest=pd.DataFrame(data_transformed_xtest,columns=pred_var)\n",
    "data_transformed_xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.DataFrame(y_train).reset_index(drop=True)\n",
    "y_train.columns=['Loan_Status']\n",
    "\n",
    "y_test=pd.DataFrame(y_test).reset_index(drop=True)\n",
    "y_test.columns=['Loan_Status']\n",
    "\n",
    "y_train=preprocess.encodingTargetVariable(y_train)\n",
    "y_test=preprocess.encodingTargetVariable(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Befor you run this code \n",
    "\n",
    "You have to install below libraries\n",
    "\n",
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_c = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_c.fit(data_transformed_xtrain,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03317225, 0.02385903, 0.06451152, 0.06397067, 0.06561121,\n",
       "       0.05422448, 0.3862864 , 0.06087452, 0.04451232, 0.05335915,\n",
       "       0.04032024, 0.08501939, 0.02427877], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feat_imp = pd.Series(model.booster().get_fscore()).sort_values(ascending=False)\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,target,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        \n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        \n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=y_train)\n",
    "        \n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        \n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], y_train,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_train, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(model.feature_importances_).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.8228\n",
      "AUC Score (Train): 0.877822\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAELCAYAAADDZxFQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfZweZX3v8c+XIOE5gKwoCZCAoQpWwbOgR9Ta8hShEKtYI9WCUCkWir6sPcaHg21Qi7RV+0CPRo2HQjHyYOmqwYAInCqiu0AEAqSEgGQJwkKAIKRA4Hv+mFkcltnNbHLfu3c23/frdb925pq55vrd9yb3b+e6Zq6RbSIiIobaYrwDiIiIzpQEERERtZIgIiKiVhJERETUSoKIiIhaSRAREVErCSIiImolQcSYknSPpLWSfl157b6Rx3ybpP5Wxdiwzf8r6bNj2eZwJP2VpAvGO46YeJIgYjwcY3v7ymvVeAYjacvxbH9jbMqxR+dLgoiOIemNkq6T9KikX0h6W2XbByTdLulxSSsk/WlZvh1wObB79Yxk6F/4Q88yyjOZj0u6GXhC0pZlvUslDUi6W9IZDeOeLslljCslPSLpVEkHSbq5fD//XNn/REk/kfRPkh6TdIekQyvbd5fUI2m1pOWSPljZ9leSLpF0gaQ1wKnAJ4H3lO/9FyN9XtXPQtJfSHpQ0v2SPlDZvo2kv5f0yzK+H0vapsHv6MSyrcfLz++Pmnx+0bny10d0BElTge8D7wd+ABwKXCrpVbYHgAeB3wdWAG8FLpfUa/tGSW8HLrA9rXK8Js2+FzgaeAh4Dvgu8B9l+TTgh5KW2V7c8G28AZhZxtdTvo/DgJcAN0m62Pa1lX0vAXYF3gl8R9IM26uBbwFLgd2BVwFXSlph+6qy7mzg3cAfA5PLY7zS9vsqsQz7eZXbXw5MAaYChwOXSLrM9iPA3wH7A28CflXG+txIvyPgSeAfgYNsL5P0CmCXhp9bdKicQcR4uKz8C/RRSZeVZe8DFtleZPs521cCfcBRALa/b/suF64FrgDespFx/KPtlbbXAgcBXbbn2X7a9grga8CcURzvLNv/bfsK4AngW7YftH0f8J/AgZV9HwS+bPsZ298GlgFHS9oDeDPw8fJYS4CvU3wpD/qp7cvKz2ltXSANPq9ngHll+4uAXwO/JWkL4CTgw7bvs/2s7etsP8V6fkcUSfY1kraxfb/tpaP47KIDJUHEeHiH7Z3K1zvKsr2Ad1cSx6MUX5SvAJD0dknXl90uj1J8Ke26kXGsrCzvRdFNVW3/k8BuozjeA5XltTXr21fW7/MLZ8r8JcUZw+7AatuPD9k2dZi4azX4vB62va6y/mQZ367A1sBdNYcd9ndk+wngPRRdXvdL+n55ZhGbsCSI6BQrgfMriWMn29vZPlvSZOBSiq6P3WzvBCwCBvuR6qYkfgLYtrL+8pp9qvVWAncPaX8H20fV1GuFqXphP9iewKrytYukHYZsu2+YuF+03uDzGslDwH8D+9RsG/Z3BGB7se3DKZL6HRRnYLEJS4KITnEBcIykIyVNkrR1OZg6DdiKoq99AFhXjjkcUan7APBSSVMqZUuAoyTtIunlwEfW0/7PgTXlwPU2ZQyvkXRQy97hC70MOEPSSyS9G3g1RffNSuA64G/Kz+C1wMnAv41wrAeA6WX3EKz/8xqW7eeABcAXy8HySZL+Z5l0hv0dSdpN0rEqLhp4iqLL6tlRfibRYZIgoiOUX4yzKbp1Bij+Wv1LYIuyu+UM4CLgEeB4ikHgwbp3UAzsrii7PnYHzgd+AdxD0f/+7fW0/yxwDHAAcDfFX9JfpxjIbYefUQxoPwR8DjjO9sPltvcC0ynOJv4d+EzZ3z+ci8ufD0u6cX2fVwMfA24BeoHVwBcofg/D/o7K11+UMa8Gfgf4s1G0GR1IeWBQxNiSdCLwJ7bfPN6xRIwkZxAREVErCSIiImqliykiImrlDCIiImq1NUFImiVpWTmfzNwR9jtOxVw23ZWyT5T1lkk6sp1xRkTEi7VtLiZJk4BzKeZ56Qd6JfXYvm3IfjtQXJL3s0rZfhRTHOxPcWfpDyXtW16KWGvXXXf19OnTW/4+IiImshtuuOEh211129o5Wd/BwPJyThskLaS4hvq2IfudBZxDce31oNnAwnL+l7slLS+P99PhGps+fTp9fX0tDD8iYuKT9MvhtrWzi2kqL5wzpp8XzieDpAOBPWx/b7R1IyKivdqZIOrmfXn+kqlyWoAvUdx9Oaq6lWOcIqlPUt/AwMAGBxoRES/WzgTRD+xRWZ9GcRv+oB2A1wDXSLoHeCPQUw5Ur68uALbn2+623d3VVduFFhERG6idCaIXmClphqStKAadq/PnPGZ7V9vTbU8HrgeOtd1X7jdH0mRJMyjmrPl5G2ONiIgh2jZIbXudpNOBxcAkYIHtpZLmAX22h508rNzvIooB7XXAaSNdwRQREa03Ye6k7u7udq5iiogYHUk32O6u25Y7qSMiolYSRERE1GrnjXIdY/rc74+6zj1nH92GSCIiNh05g4iIiFpJEBERUSsJIiIiaiVBRERErSSIiIiolQQRERG1kiAiIqJWEkRERNRKgoiIiFpJEBERUSsJIiIiaiVBRERErSSIiIiolQQRERG1kiAiIqJWWxOEpFmSlklaLmluzfZTJd0iaYmkH0varyyfLmltWb5E0lfaGWdERLxY2x4YJGkScC5wONAP9ErqsX1bZbcLbX+l3P9Y4IvArHLbXbYPaFd8ERExsnaeQRwMLLe9wvbTwEJgdnUH22sqq9sBbmM8ERExCu1MEFOBlZX1/rLsBSSdJuku4BzgjMqmGZJuknStpLfUNSDpFEl9kvoGBgZaGXtExGavnQlCNWUvOkOwfa7tfYCPA58ui+8H9rR9IPBR4EJJO9bUnW+723Z3V1dXC0OPiIh2Joh+YI/K+jRg1Qj7LwTeAWD7KdsPl8s3AHcB+7YpzoiIqNHOBNELzJQ0Q9JWwBygp7qDpJmV1aOBO8vyrnKQG0l7AzOBFW2MNSIihmjbVUy210k6HVgMTAIW2F4qaR7QZ7sHOF3SYcAzwCPACWX1twLzJK0DngVOtb26XbFGRMSLtS1BANheBCwaUnZmZfnDw9S7FLi0nbFFRMTIcid1RETUSoKIiIhaSRAREVErCSIiImolQURERK0kiIiIqJUEERERtZIgIiKiVhJERETUSoKIiIhajROEpO3aGUhERHSW9SYISW+SdBtwe7n+Okn/0vbIIiJiXDU5g/gScCQw+HyGX1DMthoRERNYoy4m2yuHFD3bhlgiIqKDNJnue6WkNwEuH/xzBmV3U0RETFxNziBOBU4DplI8RvSAcj0iIiawEc8gysd+vt/2H41RPBER0SFGPIOw/Swwe4xiiYiIDtKki+knkv5Z0lskvX7w1eTgkmZJWiZpuaS5NdtPlXSLpCWSfixpv8q2T5T1lkk6chTvKSIiWqDJIPWbyp/zKmUGfm+kSmX31LnA4RRjF72SemzfVtntQttfKfc/FvgiMKtMFHOA/YHdgR9K2rc8o4mIiDGw3gRh+3c38NgHA8ttrwCQtJCiu+r5BGF7TWX/7SgSD+V+C20/BdwtaXl5vJ9uYCwRETFKTe6kniLpi5L6ytffS5rS4NhTger9E/1l2dDjnybpLuAciktoR1P3lMG4BgYGGoQUERFNNRmDWAA8Dvxh+VoDfLNBPdWU+UUF9rm29wE+Dnx6lHXn2+623d3V1dUgpIiIaKrJGMQ+tt9VWf9rSUsa1OsH9qisTwNWjbD/QuD/bGDdiIhosSZnEGslvXlwRdIhwNoG9XqBmZJmlHdgzwF6qjtImllZPRq4s1zuAeZImixpBjAT+HmDNiMiokWanEF8CDivMu7wCHDi+irZXifpdGAxMAlYYHuppHlAn+0e4HRJhwHPlMc9oay7VNJFFAPa64DTcgVTRMTYanIV0xLgdZJ2LNfXrKdKte4iYNGQsjMryx8eoe7ngM81bSsiIlqryVVMn5e0k+01ttdI2lnSZ8ciuIiIGD9NxiDebvvRwRXbjwBHtS+kiIjoBE0SxCRJkwdXJG0DTB5h/4iImACaDFJfAFwl6ZsU9yKcBJzX1qgiImLcNRmkPkfSzcBhZdFZthe3N6yIiBhvTc4gsP0DSb0Uz6J+qL0hRUREJxh2DELS9yS9plx+BXArRffS+ZI+MkbxRUTEOBlpkHqG7VvL5Q8AV9o+BngDRaKIiIgJbKQE8Uxl+VDKG95sPw48186gIiJi/I00BrFS0p9TTJz3euAH8Pxlri8Zg9giImIcjXQGcTLFE91OBN5TuVnujTSb7jsiIjZhw55B2H4QOLWm/Grg6nYGFRER46/JndQREbEZSoKIiIhaSRAREVGryXTf+0q6StKt5fprJX16ffUiImLT1uQM4mvAJyjvi7B9M8XjQyMiYgJrkiC2tT30edDr2hFMRER0jiYJ4iFJ+1BM9Y2k44D7mxxc0ixJyyQtlzS3ZvtHJd0m6eayG2uvyrZnJS0pXz0N309ERLRIk9lcTwPmA6+SdB9wN/C+9VWSNAk4Fzic4m7sXkk9tm+r7HYT0G37SUkfAs4B3lNuW2v7gOZvJSIiWqnJ8yBWAIdJ2g7YopyLqYmDgeVlfSQtBGYDzyeI8qa7QdfTIPFERMTYaHIV0+cl7WT7CduPS9pZ0mcbHHsqsLKy3l+WDedk4PLK+taS+iRdL+kdw8R2SrlP38DAQIOQIiKiqSZjEG+vzMOE7UeAoxrUU02Za3eU3gd0A39bKd7TdjdwPPDlchzkhQez59vutt3d1dXVIKSIiGiqSYKYJGny4Eo5m+vkEfYf1A/sUVmfBqwaupOkw4BPAcfafmqw3Paq8ucK4BrgwAZtRkREizRJEBcAV0k6WdJJwJXAeQ3q9QIzJc2QtBXFvRMvuBpJ0oHAVymSw4OV8p0Hk5KkXYFDqIxdRERE+zUZpD5H0i0UDw0ScJbtxQ3qrZN0OrAYmAQssL1U0jygz3YPRZfS9sDFkgDutX0s8Grgq5Keo0hiZw+5+ikiItqsyWWu2L6cFw4gN2J7EeWT6CplZ1aWDxum3nXAb4+2vYiIaJ0mVzG9U9Kdkh6TtEbS45LWjEVwERExfpqcQZwDHGP79nYHExERnaPJIPUDSQ4REZufJmcQfZK+DVwGVC9D/U7booqIiHHXJEHsCDwJHFEpM5AEERExgTW5zPUDYxFIRER0lvUmCElbU8yTtD+w9WC57ZPaGFdERIyzJoPU5wMvB44ErqWYMqPpjK4REbGJapIgXmn7fwNP2D4POJrcxBYRMeE1SRDPlD8flfQaYAowvW0RRURER2hyFdN8STsDn6aYbG974H+3NaqIiBh3TRLEVeUzIP4fsDeApBltjSoiIsZdky6mS2vKLml1IBER0VmGPYOQ9CqKS1unSHpnZdOOVC53jYiIiWmkLqbfAn4f2Ak4plL+OPDBdgYVERHjb9gEYfs/JH0P+Ljtz49hTBER0QFGHIOw/Sxw+BjFEhERHaTJIPV1kv5Z0lskvX7w1eTgkmZJWiZpuaS5Nds/Kuk2STdLukrSXpVtJ5QPKrpT0gmjeE8REdECTS5zfVP5c16lzMDvjVRJ0iTgXIozkH6gV1LPkGdL3wR0235S0ocoHk70Hkm7AJ8Busu2bijrPtLkTUVExMZrMpvr727gsQ8GltteASBpITAbeD5B2L66sv/1wPvK5SOBK22vLuteCcwCvrWBsURExCg1eSb1FElflNRXvv5e0pQGx54KrKys95dlwzkZuHwD60ZERIs1GYNYQHFp6x+WrzXANxvUU02Za3eU3kfRnfS3o6kr6ZTBxDUwMNAgpIiIaKpJgtjH9mdsryhff0055cZ69AN7VNanAauG7iTpMOBTwLG2nxpNXdvzbXfb7u7q6moQUkRENNUkQayV9ObBFUmHAGsb1OsFZkqaIWkrYA7FZH/Pk3Qg8FWK5PBgZdNi4AhJO5cTBR5RlkVExBhpchXTh4DzynEHAauB9V52anudpNMpvtgnAQtsL5U0D+iz3UPRpbQ9cLEkgHttH2t7taSzKJIMwLzBAeuIiBgbTa5iWgK8TtKO5fqapge3vQhYNKTszMryYSPUXUAx/hEREeOgyVVML5X0j8A1wNWS/kHSS9seWUREjKsmYxALgQHgXcBx5fK32xlURESMvyZjELvYPquy/llJ72hXQBER0RmanEFcLWmOpC3K1x8C3293YBERMb6aJIg/BS4Eni5fC4GPSnpcUuMB64iI2LQ0uYpph7EIJCIiOkuTMQgkvRaYXt3f9nfaFFNERHSA9SYISQuA1wJLgefKYgNJEBERE1iTM4g32t6v7ZFERERHaTJI/VNJSRAREZuZJmcQ51EkiV8BT1HMx2Tbr21rZBERMa6aJIgFwPuBW/jNGERERExwTRLEveXMqxERsRlpkiDukHQh8F2KLiYgl7lGREx0TRLENhSJ4YhKWS5zjYiY4JrcSf2BsQgkIiI6y7AJQtI/UZwp1LJ9RlsiioiIjjDSGUTfmEUREREdZ9gEYfu8jT24pFnAP1A8k/rrts8esv2twJcppvKYY/uSyrZnKS6thfJZ1RsbT0RENNdosr4NIWkScC5wONAP9ErqsX1bZbd7gROBj9UcYq3tA9oVX0REjKxtCQI4GFhuewWApIXAbOD5BGH7nnJbbsCLiOgwTeZi2lBTgZWV9f6yrKmtJfVJuj6POI2IGHvrTRCS9pV0laRby/XXSvp0g2OrpmzYq6Jq7Gm7Gzge+LKkfWpiO6VMIn0DAwOjOHRERKxPkzOIrwGfAJ4BsH0zMKdBvX5gj8r6NGBV08Bsryp/rgCuAQ6s2We+7W7b3V1dXU0PHRERDTRJENva/vmQsnUN6vUCMyXNkLQVRVJpNKeTpJ0lTS6XdwUOoTJ2ERER7dckQTxUdu8YQNJxwP3rq2R7HXA6sBi4HbjI9lJJ8yQdWx7rIEn9wLuBr0paWlZ/NdAn6RfA1cDZQ65+ioiINmtyFdNpwHzgVZLuA+4G/qjJwW0vAhYNKTuzstxL0fU0tN51wG83aSMiItpjxAQhaQug2/ZhkrYDtrD9+NiEFhER42nELibbz1F0E2H7iSSHiIjNR5MxiCslfUzSHpJ2GXy1PbKIiBhXTcYgTip/nlYpM7B368OJiIhO0eR5EDPGIpCIiOgs600Qkv64rtz2v7Y+nIiI6BRNupgOqixvDRwK3AgkQURETGBNupj+vLouaQpwftsiioiIjrAhs7k+CcxsdSAREdFZmoxBfJffzMK6BbAfcHE7g4qIiPHXZAzi7yrL64Bf2u5vUzwREdEhmnQxHWX72vL1E9v9kr7Q9sgiImJcNUkQh9eUvb3VgURERGcZtotJ0oeAPwP2lnRzZdMOwE/aHVhERIyvkcYgLgQuB/4GmFspf9z26rZGFRER427YBGH7MeAx4L0Akl5GcaPc9pK2t33v2IQYERHjYb1jEJKOkXQnxYOCrgXuoTiziIiICazJIPVngTcC/1VO3HcoGYOIiJjwmiSIZ2w/DGwhaQvbVwMHNDm4pFmSlklaLmluzfa3SrpR0rryWdfVbSdIurN8ndDo3URERMs0uVHuUUnbA/8J/JukBylumBuRpEnAuRSXyfYDvZJ6bN9W2e1e4ETgY0Pq7gJ8BuimuIv7hrLuIw3ijYiIFmhyBjGbYv6ljwA/AO4CjmlQ72Bgue0Vtp8GFpbHep7te2zfDDw3pO6RwJW2V5dJ4UpgVoM2IyKiRZrM5vqEpL2AmbbPk7QtMKnBsacCKyvr/cAbGsZVV3fq0J0knQKcArDnnns2PHRERDTR5CqmDwKXAF8ti6YClzU4tmrKXFO2wXVtz7fdbbu7q6ur4aEjIqKJJl1MpwGHAGsAbN8JvKxBvX5gj8r6NGBVw7g2pm5ERLRAkwTxVDmGAICkLWl2JtALzJQ0Q9JWwBygp2Fci4EjJO0saWfgiLIsIiLGSJMEca2kTwLbSDqc4lkQ311fJdvrgNMpvthvBy6yvVTSPEnHAkg6SFI/8G7gq5KWlnVXA2dRJJleYF6m94iIGFtNLnOdC5wM3AL8KbAI+HqTg9teVO5fLTuzstxL0X1UV3cBsKBJOxER0Xojzea6p+17bT8HfK18RUTEZmKkLqbnr1SSdOkYxBIRER1kpC6m6qWme7c7kIlg+tzvj7rOPWcf3YZIIiI23khnEB5mOSIiNgMjnUG8TtIaijOJbcplynXb3rHt0UVExLgZ6YFBTabTiIiICarJfRAREbEZSoKIiIhaSRAREVErCSIiImolQURERK0kiIiIqJUEERERtZrM5hodZKym88i0IRGRBBHjKokoonMlQcRmIYkoYvQyBhEREbWSICIiolZbE4SkWZKWSVouaW7N9smSvl1u/5mk6WX5dElrJS0pX19pZ5wREfFibRuDkDQJOBc4HOgHeiX12L6tstvJwCO2XylpDvAF4D3ltrtsH9Cu+CJaLVeYxUTTzjOIg4HltlfYfhpYCMwess9s4Lxy+RLgUEkiIiLGXTsTxFRgZWW9vyyr3cf2OuAx4KXlthmSbpJ0raS31DUg6RRJfZL6BgYGWht9RMRmrp0Jou5MYOijS4fb535gT9sHAh8FLpT0oifY2Z5vu9t2d1dX10YHHBERv9HOBNEP7FFZnwasGm4fSVsCU4DVtp+y/TCA7RuAu4B92xhrREQM0c4b5XqBmZJmAPcBc4Djh+zTA5wA/BQ4DviRbUvqokgUz0raG5gJrGhjrBExRAbDo20JwvY6SacDi4FJwALbSyXNA/ps9wDfAM6XtBxYTZFEAN4KzJO0DngWONX26nbFGhERL9bWqTZsLwIWDSk7s7L838C7a+pdClzaztgiojPkTKVz5U7qiIiolQQRERG1kiAiIqJWpvuOiAkv4xwbJmcQERFRKwkiIiJqJUFEREStJIiIiKiVQeqIiBaZaM8EyRlERETUSoKIiIhaSRAREVErCSIiImolQURERK0kiIiIqJUEERERtZIgIiKiVhJERETUamuCkDRL0jJJyyXNrdk+WdK3y+0/kzS9su0TZfkySUe2M86IiHixtiUISZOAc4G3A/sB75W035DdTgYesf1K4EvAF8q6+wFzgP2BWcC/lMeLiIgx0s4ziIOB5bZX2H4aWAjMHrLPbOC8cvkS4FBJKssX2n7K9t3A8vJ4ERExRmS7PQeWjgNm2f6Tcv39wBtsn17Z59Zyn/5y/S7gDcBfAdfbvqAs/wZwue1LhrRxCnBKufpbwLJRhrkr8NAo62yItNOZbaSdzm0j7YxdG3vZ7qrb0M7ZXFVTNjQbDbdPk7rYng/MH31oZeNSn+3uDa2fdjbtNtJO57aRdjqjjXZ2MfUDe1TWpwGrhttH0pbAFGB1w7oREdFG7UwQvcBMSTMkbUUx6NwzZJ8e4IRy+TjgRy76vHqAOeVVTjOAmcDP2xhrREQM0bYuJtvrJJ0OLAYmAQtsL5U0D+iz3QN8Azhf0nKKM4c5Zd2lki4CbgPWAafZfrYNYW5w91TamRBtpJ3ObSPtdEAbbRukjoiITVvupI6IiFpJEBERUSsJIiIiarXzPoiOIukNwO2210jaBpgLvJ5iIPzzth8b1wA3kqR/tf3HbTjuq4CpwM9s/7pSPsv2D1rYzsGAbfeWU63MAu6wvaiFbZwB/Lvtla06ZsN230wxE8Cttq9o4XH3Af6A4pLwdcCdwLda+W+5cgXiKts/lHQ88CbgdmC+7Wda1dZYKP89z6b4N22Ky+d7bN8+roF1qM1mkFrSUuB15dVV84EnKaf3KMvfOa4BjoKkoZcLC/hd4EcAto9tUTtnAKdRfBkcAHzY9n+U2260/foWtfMZijm7tgSupLib/hrgMGCx7c+1qJ3HgCeAu4BvARfbHmjFsYe083PbB5fLH6T4DP8dOAL4ru2zW9DGGcAxwLXAUcAS4BGKhPFntq/Z2DbKdv6N4veyLfAosD3wHYr/N7J9wgjVO4qkjwPvpZj2p78snkaRABe24vfSKSR9wPY3N/pAtjeLF8XZw+DyjUO2LRmjGC5v0XFuBC4A3gb8Tvnz/nL5d1oY7y3A9uXydKCPIkkA3NTidiZRfAmtAXYsy7cBbm5hOzdRdKseQXGJ9QDwA4p7cXZoZTuV5V6gq1zeDrillZ9ZubwtcE25vGeLfzc3lz+3BB6otKkW/26mAGcDdwAPl6/by7KdWtTGfwEvqSnfCrizVe+lPOaOwN8A5wPHD9n2L61sa5j2723FcTabLibg1kpW/YWkbtt9kvYFWnaaLGm4v6pF8Vd4K3QDHwY+Bfyl7SWS1tq+tkXHHzTJZbeS7XskvQ24RNJe1E+HsqHWubjP5UlJd9leU7a5VtJzLWzHtp8DrgCukPQSijOX9wJ/B9TOR7MBtpC0M0UyksuzFNtPSFrXojag+NJ+FpgM7FC2cW/5vlpli7KbaTuKRDQ428FkoJXtXERxBvw2278CkPRyiuR9MXB4C9p4Dtgd+OWQ8leU21rpmxRdfpcCJ0l6F0WieAp4YysakHTzcJuA3VrRxuaUIP4E+AdJn6aYzOqnklYCK8ttrdJLcdpf9wW6UysaKL/kviTp4vLnA7Tnd/krSQfYXlK2+2tJvw8sAH67he08LWlb208C/2OwUNIUWvsf9wW/Exf95z1ATzku1SpTgBvK9izp5bZ/JWn7oTFshK8DvZKuB97Kb6bK76L4Am+Vb1D8VT+J4g+SiyWtoPiSW9jCdqbb/kK1oEwUX5B0Uova+AhwlaQ7Kf7fQ3HG9Urg9GFrbZh9bL+rXL5M0qeAH0lqSfdvaTfgSIquxSoB17Wigc1mDGKQpB2AvSm+UPttP9Di498K/IHtO2u2rbS9R021jW3zaOAQ259s8XGnUfx1/6uabYfY/kmL2plc/mU1tHxX4BW2b2lRO/va/q9WHGsD298W2M3FFPatON7+wKspBr/vaMUxh2lndwDbqyTtRDE2dK/tlk1/I+kK4IfAeYP/JyXtBpwIHG77sBa1swXFBQNTKb5I+4Fet3imBkm3A/uXf8wNlp0A/C+Kbtu9WtDGN4Bv2v5xzbYLbRVAGPYAAADTSURBVB+/0W1sbgmi3cppzm+x/aKpxyW9w/Zl4xBWREcru+TmUlxh9LKy+AGKM7yzbQ/9K7mjSToHuML2D4eUzwL+yfbM8YlsdJIgxlDLriyI2IxMtP83m9L7SYIYQ5Lutb3neMcRsSmZaP9vNqX3szkNUo+JsbiyIGKimWj/bybK+0mCaL22X1kQMQFNtP83E+L9JEG03vcorlJYMnSDpGvGPpyITcJE+38zId5PxiAiIqJWZnONiIhaSRAREVErCSIiImolQURERK0kiIiIqPX/AXKJRBYBspDPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in data_transformed_xtrain.columns if x not in [y_train]]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "modelfit(xgb1,data_transformed_xtrain,predictors,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
