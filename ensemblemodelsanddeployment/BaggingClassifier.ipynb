{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Office\n",
    "os.chdir('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\NITDATA\\\\Algorithms\\\\codesnippetsforbaggingandboostingalgorithms')\n",
    "data = pd.read_csv('train_u6lujuX_CVtuZ9i.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle\n",
    "\n",
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ## Here this model will be called with a variable (df), which is a dataframe\n",
    "    def datapreprocessing(self, df):\n",
    "        \n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        df.loc[df['Gender'].isnull(),'Gender']='Trasgender'\n",
    "        df.loc[df['Dependents'].isnull(),'Dependents']='0'\n",
    "        df.loc[df['Education'].isnull(),'Education']='No Education'\n",
    "        df.loc[df['Married'].isnull(),'Married']='No'\n",
    "        df.loc[df['Self_Employed'].isnull(),'Self_Employed']='No'\n",
    "        df.loc[df['Loan_Amount_Term'].isnull(),'Loan_Amount_Term']=0\n",
    "        df.loc[df['Credit_History'].isnull(),'Credit_History']=0\n",
    "        df.loc[df['LoanAmount'].isnull(),'LoanAmount']=146.867     \n",
    "        df['Credit_History']=df['Credit_History'].astype(str)\n",
    "        \n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        MinMaxpickle_in = open(\"minmax_pickle.pkl\",\"rb\")\n",
    "        MinmaxScaler_dict = pickle.load(MinMaxpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['ApplicantIncome']=pd.DataFrame(MinmaxScaler_dict['ApplicantIncome'].transform(df[['ApplicantIncome']]))\n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        standardscaler_in = open(\"standardscaler_pickle.pkl\",\"rb\")\n",
    "        standardscaler_dict = pickle.load(standardscaler_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['LoanAmount']=pd.DataFrame(standardscaler_dict['LoanAmount'].transform(df[['LoanAmount']]))\n",
    "        \n",
    "        ## Creating a Instance for the LabelEncoder Pickle File\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Education']=pd.DataFrame(Labelencoder_dict['Education'].transform(df[['Education']]))\n",
    "        df['Property_Area']=pd.DataFrame(Labelencoder_dict['Property_Area'].transform(df[['Property_Area']]))\n",
    "        df['Credit_History']=pd.DataFrame(Labelencoder_dict['Credit_History'].transform(df[['Credit_History']]))\n",
    "        df['Dependents']=pd.DataFrame(Labelencoder_dict['Dependents'].transform(df[['Dependents']]))\n",
    "        \n",
    "        ## Creating a Instance for the binarizer Pickle File\n",
    "        Onehotpickle_in = open(\"binarizer_pickle.pkl\",\"rb\")\n",
    "        Onehot_dict = pickle.load(Onehotpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        d1=pd.DataFrame(Onehot_dict['Self_Employed'].transform(df[['Self_Employed']]))\n",
    "        d1.columns=['Self_Employed_0']\n",
    "        d2=pd.DataFrame(Onehot_dict['Married'].transform(df[['Married']]))\n",
    "        d2.columns=['Married_0']\n",
    "        d3=pd.DataFrame(Onehot_dict['Gender'].transform(df[['Gender']]))\n",
    "        d3.columns=['Gender_0','Gender_1','Gender_2']\n",
    "    \n",
    "        df=df.drop(['Self_Employed','Married','Gender','Loan_ID'],axis=1)\n",
    "        df=pd.concat([df,d1,d2,d3],axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def definingvalues(self, df, y=None,**fit_params):\n",
    "        self.term_mean_ = df['Loan_Amount_Term'].mean()\n",
    "        self.amt_mean_ = df['LoanAmount'].mean()\n",
    "        return self\n",
    "    \n",
    "    def encodingTargetVariable(self,df):\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Loan_Status']=pd.DataFrame(Labelencoder_dict['Loan_Status'].transform(df[['Loan_Status']]))\n",
    "        \n",
    "        return df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_var = ['Loan_ID','Gender','Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History', 'Property_Area']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[pred_var], data['Loan_Status'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating an instance for the class\n",
    "preprocess = PreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the fit function present in the class Preprocessing\n",
    "preprocess.definingvalues(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_train dataset\n",
    "data_transformed_xtrain = preprocess.datapreprocessing(X_train)\n",
    "\n",
    "pred_var = ['Dependents', 'Education', 'ApplicantIncome',\n",
    "       'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History',\n",
    "       'Property_Area', 'Self_Employed_0', 'Married_0', 'Gender_0', 'Gender_1','Gender_2']\n",
    "\n",
    "\n",
    "data_transformed_xtrain=pd.DataFrame(data_transformed_xtrain,columns=pred_var)\n",
    "data_transformed_xtrain.head()\n",
    "\n",
    "print(data_transformed_xtrain.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformed_xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_test dataset\n",
    "data_transformed_xtest = preprocess.datapreprocessing(X_test)\n",
    "\n",
    "# Converting the matrix to a dataframe\n",
    "data_transformed_xtest=pd.DataFrame(data_transformed_xtest,columns=pred_var)\n",
    "data_transformed_xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.DataFrame(y_train).reset_index(drop=True)\n",
    "y_train.columns=['Loan_Status']\n",
    "\n",
    "y_test=pd.DataFrame(y_test).reset_index(drop=True)\n",
    "y_test.columns=['Loan_Status']\n",
    "\n",
    "y_train=preprocess.encodingTargetVariable(y_train)\n",
    "y_test=preprocess.encodingTargetVariable(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "import os\n",
    "# Office\n",
    "os.chdir('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\NITDATA\\\\Algorithms\\\\codesnippetsforbaggingandboostingalgorithms')\n",
    "data = pd.read_csv('train_u6lujuX_CVtuZ9i.csv')\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle\n",
    "\n",
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ## Here this model will be called with a variable (df), which is a dataframe\n",
    "    def datapreprocessing(self, df):\n",
    "        \n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        df.loc[df['Gender'].isnull(),'Gender']='Trasgender'\n",
    "        df.loc[df['Dependents'].isnull(),'Dependents']='0'\n",
    "        df.loc[df['Education'].isnull(),'Education']='No Education'\n",
    "        df.loc[df['Married'].isnull(),'Married']='No'\n",
    "        df.loc[df['Self_Employed'].isnull(),'Self_Employed']='No'\n",
    "        df.loc[df['Loan_Amount_Term'].isnull(),'Loan_Amount_Term']=0\n",
    "        df.loc[df['Credit_History'].isnull(),'Credit_History']=0\n",
    "        df.loc[df['LoanAmount'].isnull(),'LoanAmount']=146.867     \n",
    "        df['Credit_History']=df['Credit_History'].astype(str)\n",
    "        \n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        MinMaxpickle_in = open(\"minmax_pickle.pkl\",\"rb\")\n",
    "        MinmaxScaler_dict = pickle.load(MinMaxpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['ApplicantIncome']=pd.DataFrame(MinmaxScaler_dict['ApplicantIncome'].transform(df[['ApplicantIncome']]))\n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        standardscaler_in = open(\"standardscaler_pickle.pkl\",\"rb\")\n",
    "        standardscaler_dict = pickle.load(standardscaler_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['LoanAmount']=pd.DataFrame(standardscaler_dict['LoanAmount'].transform(df[['LoanAmount']]))\n",
    "        \n",
    "        ## Creating a Instance for the LabelEncoder Pickle File\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Education']=pd.DataFrame(Labelencoder_dict['Education'].transform(df[['Education']]))\n",
    "        df['Property_Area']=pd.DataFrame(Labelencoder_dict['Property_Area'].transform(df[['Property_Area']]))\n",
    "        df['Credit_History']=pd.DataFrame(Labelencoder_dict['Credit_History'].transform(df[['Credit_History']]))\n",
    "        df['Dependents']=pd.DataFrame(Labelencoder_dict['Dependents'].transform(df[['Dependents']]))\n",
    "        \n",
    "        ## Creating a Instance for the binarizer Pickle File\n",
    "        Onehotpickle_in = open(\"binarizer_pickle.pkl\",\"rb\")\n",
    "        Onehot_dict = pickle.load(Onehotpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        d1=pd.DataFrame(Onehot_dict['Self_Employed'].transform(df[['Self_Employed']]))\n",
    "        d1.columns=['Self_Employed_0']\n",
    "        d2=pd.DataFrame(Onehot_dict['Married'].transform(df[['Married']]))\n",
    "        d2.columns=['Married_0']\n",
    "        d3=pd.DataFrame(Onehot_dict['Gender'].transform(df[['Gender']]))\n",
    "        d3.columns=['Gender_0','Gender_1','Gender_2']\n",
    "    \n",
    "        df=df.drop(['Self_Employed','Married','Gender','Loan_ID'],axis=1)\n",
    "        df=pd.concat([df,d1,d2,d3],axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def definingvalues(self, df, y=None,**fit_params):\n",
    "        self.term_mean_ = df['Loan_Amount_Term'].mean()\n",
    "        self.amt_mean_ = df['LoanAmount'].mean()\n",
    "        return self\n",
    "    \n",
    "    def encodingTargetVariable(self,df):\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Loan_Status']=pd.DataFrame(Labelencoder_dict['Loan_Status'].transform(df[['Loan_Status']]))\n",
    "        \n",
    "        return df.as_matrix()\n",
    "\n",
    "data.columns\n",
    "\n",
    "pred_var = ['Loan_ID','Gender','Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History', 'Property_Area']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[pred_var], data['Loan_Status'], test_size=0.30, random_state=42)\n",
    "\n",
    "## Creating an instance for the class\n",
    "preprocess = PreProcessing()\n",
    "\n",
    "# Calling the fit function present in the class Preprocessing\n",
    "preprocess.definingvalues(X_train)\n",
    "\n",
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_train dataset\n",
    "data_transformed_xtrain = preprocess.datapreprocessing(X_train)\n",
    "\n",
    "pred_var = ['Dependents', 'Education', 'ApplicantIncome',\n",
    "       'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History',\n",
    "       'Property_Area', 'Self_Employed_0', 'Married_0', 'Gender_0', 'Gender_1','Gender_2']\n",
    "\n",
    "\n",
    "data_transformed_xtrain=pd.DataFrame(data_transformed_xtrain,columns=pred_var)\n",
    "data_transformed_xtrain.head()\n",
    "\n",
    "print(data_transformed_xtrain.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "data_transformed_xtrain.columns\n",
    "\n",
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_test dataset\n",
    "data_transformed_xtest = preprocess.datapreprocessing(X_test)\n",
    "\n",
    "# Converting the matrix to a dataframe\n",
    "data_transformed_xtest=pd.DataFrame(data_transformed_xtest,columns=pred_var)\n",
    "data_transformed_xtest.head()\n",
    "\n",
    "y_train=pd.DataFrame(y_train).reset_index(drop=True)\n",
    "y_train.columns=['Loan_Status']\n",
    "\n",
    "y_test=pd.DataFrame(y_test).reset_index(drop=True)\n",
    "y_test.columns=['Loan_Status']\n",
    "\n",
    "y_train=preprocess.encodingTargetVariable(y_train)\n",
    "y_test=preprocess.encodingTargetVariable(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BagCla = BaggingClassifier(base_estimator=LogisticRegression(C=10,penalty='l2'),n_estimators=10, \n",
    "                           random_state=0,max_features=0.5,max_samples=0.8)\n",
    "BagCla.fit(data_transformed_xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BagCla.predict(data_transformed_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BagCla.predict_proba(data_transformed_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
