{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Office\n",
    "os.chdir('C:\\\\Users\\\\prudi\\\\Documents\\\\GitHub\\\\Code\\\\NITDATA\\\\Algorithms\\\\codesnippetsforbaggingandboostingalgorithms')\n",
    "data = pd.read_csv('train_u6lujuX_CVtuZ9i.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle\n",
    "\n",
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    ## Here this model will be called with a variable (df), which is a dataframe\n",
    "    def datapreprocessing(self, df):\n",
    "        \n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        df.loc[df['Gender'].isnull(),'Gender']='Trasgender'\n",
    "        df.loc[df['Dependents'].isnull(),'Dependents']='0'\n",
    "        df.loc[df['Education'].isnull(),'Education']='No Education'\n",
    "        df.loc[df['Married'].isnull(),'Married']='No'\n",
    "        df.loc[df['Self_Employed'].isnull(),'Self_Employed']='No'\n",
    "        df.loc[df['Loan_Amount_Term'].isnull(),'Loan_Amount_Term']=0\n",
    "        df.loc[df['Credit_History'].isnull(),'Credit_History']=0\n",
    "        df.loc[df['LoanAmount'].isnull(),'LoanAmount']=146.867     \n",
    "        df['Credit_History']=df['Credit_History'].astype(str)\n",
    "        \n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        MinMaxpickle_in = open(\"minmax_pickle.pkl\",\"rb\")\n",
    "        MinmaxScaler_dict = pickle.load(MinMaxpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['ApplicantIncome']=pd.DataFrame(MinmaxScaler_dict['ApplicantIncome'].transform(df[['ApplicantIncome']]))\n",
    "        \n",
    "        ## Creating a Instance for the minmax Pickle File\n",
    "        standardscaler_in = open(\"standardscaler_pickle.pkl\",\"rb\")\n",
    "        standardscaler_dict = pickle.load(standardscaler_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['LoanAmount']=pd.DataFrame(standardscaler_dict['LoanAmount'].transform(df[['LoanAmount']]))\n",
    "        \n",
    "        ## Creating a Instance for the LabelEncoder Pickle File\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Education']=pd.DataFrame(Labelencoder_dict['Education'].transform(df[['Education']]))\n",
    "        df['Property_Area']=pd.DataFrame(Labelencoder_dict['Property_Area'].transform(df[['Property_Area']]))\n",
    "        df['Credit_History']=pd.DataFrame(Labelencoder_dict['Credit_History'].transform(df[['Credit_History']]))\n",
    "        df['Dependents']=pd.DataFrame(Labelencoder_dict['Dependents'].transform(df[['Dependents']]))\n",
    "        \n",
    "        ## Creating a Instance for the binarizer Pickle File\n",
    "        Onehotpickle_in = open(\"binarizer_pickle.pkl\",\"rb\")\n",
    "        Onehot_dict = pickle.load(Onehotpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        d1=pd.DataFrame(Onehot_dict['Self_Employed'].transform(df[['Self_Employed']]))\n",
    "        d1.columns=['Self_Employed_0']\n",
    "        d2=pd.DataFrame(Onehot_dict['Married'].transform(df[['Married']]))\n",
    "        d2.columns=['Married_0']\n",
    "        d3=pd.DataFrame(Onehot_dict['Gender'].transform(df[['Gender']]))\n",
    "        d3.columns=['Gender_0','Gender_1','Gender_2']\n",
    "    \n",
    "        df=df.drop(['Self_Employed','Married','Gender','Loan_ID'],axis=1)\n",
    "        df=pd.concat([df,d1,d2,d3],axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def definingvalues(self, df, y=None,**fit_params):\n",
    "        self.term_mean_ = df['Loan_Amount_Term'].mean()\n",
    "        self.amt_mean_ = df['LoanAmount'].mean()\n",
    "        return self\n",
    "    \n",
    "    def encodingTargetVariable(self,df):\n",
    "        Labelencoderpickle_in = open(\"labelencoder_pickle.pkl\",\"rb\")\n",
    "        Labelencoder_dict = pickle.load(Labelencoderpickle_in)\n",
    "        \n",
    "        ## Applying the pickle file\n",
    "        df['Loan_Status']=pd.DataFrame(Labelencoder_dict['Loan_Status'].transform(df[['Loan_Status']]))\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
       "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_var = ['Loan_ID','Gender','Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History', 'Property_Area']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[pred_var], data['Loan_Status'], test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating an instance for the class\n",
    "preprocess = PreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreProcessing()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the fit function present in the class Preprocessing\n",
    "preprocess.definingvalues(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 13)\n",
      "(429, 12)\n"
     ]
    }
   ],
   "source": [
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_train dataset\n",
    "data_transformed_xtrain = preprocess.datapreprocessing(X_train)\n",
    "\n",
    "pred_var = ['Dependents', 'Education', 'ApplicantIncome',\n",
    "       'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History',\n",
    "       'Property_Area', 'Self_Employed_0', 'Married_0', 'Gender_0', 'Gender_1','Gender_2']\n",
    "\n",
    "\n",
    "data_transformed_xtrain=pd.DataFrame(data_transformed_xtrain,columns=pred_var)\n",
    "data_transformed_xtrain.head()\n",
    "\n",
    "print(data_transformed_xtrain.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dependents', 'Education', 'ApplicantIncome', 'CoapplicantIncome',\n",
       "       'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'Property_Area',\n",
       "       'Self_Employed_0', 'Married_0', 'Gender_0', 'Gender_1', 'Gender_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformed_xtrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Self_Employed_0</th>\n",
       "      <th>Married_0</th>\n",
       "      <th>Gender_0</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Gender_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.426199</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.108986</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306361</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>0.329638</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.033230</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.195851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.048895</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependents  Education  ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
       "0           0          0         0.681284                0.0    1.426199   \n",
       "1           0          0         0.317267                0.0   -0.108986   \n",
       "2           2          0         0.306361             1447.0    0.329638   \n",
       "3           0          0         0.209732                0.0   -1.033230   \n",
       "4           0          0         0.195851                0.0   -1.048895   \n",
       "\n",
       "   Loan_Amount_Term  Credit_History  Property_Area  Self_Employed_0  \\\n",
       "0             360.0               1              1                0   \n",
       "1             360.0               0              1                0   \n",
       "2             360.0               1              0                0   \n",
       "3             360.0               1              0                0   \n",
       "4             360.0               1              1                0   \n",
       "\n",
       "   Married_0  Gender_0  Gender_1  Gender_2  \n",
       "0          1         0         1         0  \n",
       "1          1         0         1         0  \n",
       "2          1         0         1         0  \n",
       "3          0         1         0         0  \n",
       "4          0         0         1         0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Calling the datapreprocessing function present in the class Preprocessing to Preprocess X_test dataset\n",
    "data_transformed_xtest = preprocess.datapreprocessing(X_test)\n",
    "\n",
    "# Converting the matrix to a dataframe\n",
    "data_transformed_xtest=pd.DataFrame(data_transformed_xtest,columns=pred_var)\n",
    "data_transformed_xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=pd.DataFrame(y_train).reset_index(drop=True)\n",
    "y_train.columns=['Loan_Status']\n",
    "\n",
    "y_test=pd.DataFrame(y_test).reset_index(drop=True)\n",
    "y_test.columns=['Loan_Status']\n",
    "\n",
    "y_train=preprocess.encodingTargetVariable(y_train)\n",
    "y_test=preprocess.encodingTargetVariable(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Befor you run this code \n",
    "\n",
    "You have to install below libraries\n",
    "\n",
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "d_train = lgb.Dataset(data_transformed_xtrain,label=y_train)\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 10\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 10\n",
    "clf = lgb.train(params, d_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few things to notice in parameters:\n",
    "\n",
    "Used ‘binary’ as objective(remember this is classification problem) \n",
    "\n",
    "Used ‘binary_logloss’ as metric(same reason, binary classification problem)\n",
    "\n",
    "‘num_leaves’=10 (as it is small data)\n",
    "\n",
    "‘boosting type’ is gbdt, we are implementing gradient boosting(you can try random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73298583, 0.65679257, 0.70934617, 0.69263431, 0.71533278,\n",
       "       0.71772889, 0.73565028, 0.70641972, 0.71020882, 0.72395681,\n",
       "       0.66354044, 0.70967663, 0.74324184, 0.7037946 , 0.72103556,\n",
       "       0.64819959, 0.6949469 , 0.7220832 , 0.73535523, 0.72816831,\n",
       "       0.71254901, 0.74073529, 0.71446906, 0.73371135, 0.70844968,\n",
       "       0.70585457, 0.71414081, 0.72258856, 0.71082472, 0.70611449,\n",
       "       0.72060246, 0.74330446, 0.74079854, 0.71279379, 0.70737362,\n",
       "       0.64276091, 0.71236134, 0.72562932, 0.74513619, 0.71787423,\n",
       "       0.7055778 , 0.72231457, 0.70908586, 0.71734031, 0.70759738,\n",
       "       0.73330975, 0.64240188, 0.64966881, 0.64552303, 0.65195596,\n",
       "       0.65524775, 0.72090577, 0.64926095, 0.69613235, 0.70738737,\n",
       "       0.70641175, 0.71044673, 0.71292985, 0.64531578, 0.73755087,\n",
       "       0.66012293, 0.65659917, 0.64891718, 0.7093476 , 0.72477172,\n",
       "       0.70120326, 0.73557379, 0.74112306, 0.72480225, 0.70747073,\n",
       "       0.63998131, 0.71843227, 0.73469491, 0.72068664, 0.65779785,\n",
       "       0.72769647, 0.71146807, 0.64448138, 0.64155215, 0.71598359,\n",
       "       0.71915545, 0.71833174, 0.73611961, 0.69746456, 0.70837583,\n",
       "       0.73817582, 0.71188941, 0.65709332, 0.72165926, 0.70870391,\n",
       "       0.73699623, 0.63918979, 0.65903002, 0.73313209, 0.73202226,\n",
       "       0.7159902 , 0.64156397, 0.65793879, 0.64286441, 0.70599644,\n",
       "       0.74041571, 0.74460504, 0.70207013, 0.71242002, 0.64546407,\n",
       "       0.64368868, 0.71576214, 0.66024826, 0.73351748, 0.69746456,\n",
       "       0.70456424, 0.6489744 , 0.71530107, 0.71163074, 0.64415405,\n",
       "       0.71027678, 0.72262945, 0.71665675, 0.70205653, 0.69263431,\n",
       "       0.74304031, 0.72688032, 0.71080554, 0.66120102, 0.74094823,\n",
       "       0.741675  , 0.74392488, 0.65078369, 0.71629759, 0.65694016,\n",
       "       0.64394921, 0.73363738, 0.70006003, 0.65854795, 0.73890654,\n",
       "       0.70628792, 0.7103221 , 0.64046798, 0.71542081, 0.73723035,\n",
       "       0.72336761, 0.73327578, 0.69833853, 0.64376256, 0.70806558,\n",
       "       0.71020042, 0.70868955, 0.70439987, 0.71039491, 0.70657126,\n",
       "       0.74199205, 0.72745443, 0.66089082, 0.70827004, 0.71853477,\n",
       "       0.71112637, 0.72260968, 0.70821356, 0.65995093, 0.69699937,\n",
       "       0.70015214, 0.70585457, 0.65058921, 0.65881366, 0.73498084,\n",
       "       0.73988991, 0.69870327, 0.70686555, 0.66401489, 0.71883387,\n",
       "       0.6576875 , 0.64520649, 0.66099201, 0.66103747, 0.71129898,\n",
       "       0.73180659, 0.73707679, 0.64026256, 0.7173071 , 0.70965913,\n",
       "       0.73838469, 0.70893619, 0.71695342, 0.71207726, 0.64659791])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf.predict(data_transformed_xtest)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformed_xtest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert into binary values\n",
    "for i in range(0,data_transformed_xtest.shape[0]):\n",
    "    if y_pred[i]>=.5:       # setting threshold to .5\n",
    "       y_pred[i]=1\n",
    "    else:  \n",
    "       y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
